\section{Direct Encoding} \label{sec:de}
We call our model the \emph{direct encoding} approach, because instead of using the whole neural network to transform the image, we decided to exploit the fact that we have a bottleneck at the hidden layer and used the state of the hidden layer nodes as the output, thus directly applying parts of the network on the image and effectively reducing data size from \(8 * 8 = 64\) bytes to 4 bytes, a compression ratio of 0.0625. In our MATLAB implementation, we use a feedforward neural network\footnote{\url{http://ch.mathworks.com/help/nnet/ref/feedforwardnet.html}}, where all layers have a connection from the previous layer.

\subsection{Training} \label{sec:trainfcn}
Similar to the \emph{direct classification} approach, we decided to train globally, i.e. we let the network train on several hundreds of pictures and took the resulting network as our universal net. In theory one could still perform a few epochs of training on the currently processed image, however we didn't see a significant improvement over the universal case. 
The training function randomly chooses several patches of the original image and uses them as input for the neural network while the target output is the same data. The weights are set accordingly during the training phase until the difference between the output and the target vector is within a desired threshold. During training, we use all parts of the topology described in section~\ref{sec:neural_net_structure}. The used training function is called \emph{trainoss}\footnote{\url{http://ch.mathworks.com/help/nnet/ref/trainoss.html}} and uses a one step secant method as described in \cite{Battiti89}. 


%%\subsection{Singular Value Decomposition}
%%The singular value decomposition(SVD) is a matrix factorization. A m$\times$n matrix M can be written as a product of three matrices U, $\Sigma$ and V$^*$, where U is a unitary m$\times$m matrix, V$^*$ is the conjugate transpose of a n$\times$n unitary matrix V and $\Sigma$ is a m$\times$n diagonal matrix. The entries on the diagonal of $\Sigma$, which are non-negativ real numbers, are called the singular values of M. The columns of U are called left singular vectors and the rows of V$^*$ are called right singular vectors of M. \\
%%SVD can be used for image compression the following way. The singular values are sorted in descending order and then only the largest singular values and the corresponding right and left singular vectors are used to save the image.
