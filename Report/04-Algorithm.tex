\section{The Algorithm}
\label{sec:algorithm}

In this section, we will briefly describe the steps our algorithm takes and then provide more details on key parts of it. The algorithm consists of two parts, a \emph{Compress} function and a \emph{Decompress} function. 

\subsection{Compression} \label{sec:compress}
In the Compress function, to which one passes the original image as an argument, the following steps are completed:
\begin{enumerate}
\item \emph{Feature extraction}. First, we add rows and columns to the image matrix so that the number of rows and columns is evenly divisible by the predefined patch size. We then extract patches of size {\color{red}X by X} and return them as a single column vector.

\item \emph{Convertion}. We convert the image data, consisting of pixels with values between 0 and 255, to real values in the range \([-1, 1]\). 

\item \emph{Training} is performed ``globally'', though one can use the existing net and improve it by training on the current image for a few epochs. In this case we improve the network performance by including a set of 100 to 300 randomly chosen column vectors of the current image in the training.

\item \emph{Network separation}. After the training is done, we separate the neural network into two parts, one including input and hidden layer and the other including hidden and output layer. The first will be our compression network, using the values of the hidden layer as the output, while the latter is the decompression network, taking the values of the hidden layer as input and returning an approximation of the original data.

\item \emph{Compression} is done by applying the compression network to the column vectors of the image, effectively reducing data size from {\color{red} X bytes to Y byte}.

\begin{figure}[tbh]
  \centering
  \includegraphics[width=\columnwidth]{images/bqQuantizer}
  \caption{Neural Network Structure for compression.}
  \label{fig:bpQuantizer}
\end{figure}

\item \emph{Quantization} as shown in Figure~\ref{fig:bpQuantizer} is the process of mapping a large set of values to a smaller set of values. After compression, we quantize the output using 4 bits for quantization levels, leaving us with 16 identically wide intervals. After mapping the compression output to these values, we store two indices per byte.

\item \emph{Transmission}. The final data structure of the compressed image consists of the compressed and quantized output, the decoding net, image size and the parameters patch size, hidden layer node count and quantization bits.
\end{enumerate}

\subsection{Decompression}
\label{sec:decompAlg}
TODO: Describe how the decompression works
